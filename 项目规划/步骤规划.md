# 简历在线编辑器：分阶段开发计划

本项目旨在构建一个生产级的在线简历编辑网站。本计划将复杂的架构分解为 5 个可管理的阶段，从最小可行产品 (MVP) 开始，逐步迭代，最终实现完整的架构蓝图。

## Phase 0: 环境与地基搭建

**目标：** 初始化项目，并让所有核心服务在 `docker-compose` 中“跑起来”。

**组件：** `Git`, `Docker Compose`, `Go (Gin)`, `Next.js`, `PostgreSQL`, `Nginx`, `Viper`

**任务：**

1.  **项目结构：**
    * [x] 初始化 Git 仓库。
    * [x] 创建顶层目录：`/backend`, `/frontend`, `/docker`。
2.  **Docker 编排 (`docker-compose.yml`)：**
    * [x] 定义所有**开发期**服务：
        * [x] `api` (后端 Go)
        * [x] `frontend` (Next.js)
        * [x] `db` (使用 `postgres:15-alpine` 镜像)
        * [x] `nginx` (使用 `nginx:1.27-alpine` 镜像)
    * [x] 配置服务间的 `depends_on` 和共享网络。
3.  **Dockerfiles：**
    * [x] `/backend/Dockerfile`: 基于 `golang:alpine`，设置工作目录，拷贝 `go.mod` 并下载依赖。
    * [x] `/frontend/Dockerfile`: 基于 `node:alpine`，设置 `package.json` 并安装 `npm` 依赖。
4.  **配置 (`Viper`)：**
    * [x] 在 `backend` 中集成 `Viper`。
    * [x] 使其能够从**环境变量**（由 `docker-compose.yml` 注入）中读取配置（如数据库连接字符串）。
5.  **反向代理 (`nginx`)：**
    * [x] 配置 `nginx.conf` 作为所有流量的入口。
    * [x] `location /` 转发到 `frontend:3000`。
    * [x] `location /api/` 转发到 `api:8080` (Gin)，并重写（rewrite）URL。
    * **关键：** 这一步能从根本上解决开发中的 `CORS` 跨域问题。
    * [x] 这样下来，由于rewrite了URL,最终的效果是外部访问 `/api/...` ,后端收到时会自动去除该前缀，保证后端接口的纯净性
**验收标准：**
* [x] 在本地运行 `docker-compose up --build`。
* [x] 访问 `http://localhost` 能看到 Next.js 的默认页面。
* [x] 访问 `http://localhost/api/health` 能收到 Gin 返回的 `{"status": "ok"}` JSON。

---

## Phase 1: 核心功能 MVP (同步实现)

**目标：** 验证最高风险的技术点：**`go-rod` PDF 导出**。我们暂时**绕过**所有异步逻辑，采用**同步**方式打通端到端的核心流程。

**组件：** `Gin`, `GORM`, `go-rod`, `Next.js`, `PostgreSQL`

**任务：**

1.  [x] **`go-rod` 攻坚（Spike）：**
    * **关键：** 修改 `/backend/Dockerfile`，在 `golang:1.25.3-alpine` 镜像中**安装 `chromium` 及其所有图形/字体依赖库**。
    * 改编一个临时的 `main.go`，用 `go-rod` 将一个写死的 HTML 字符串 (`<h1>Hello</h1>`) 保存为 `test.pdf`。
    * 运行 `docker-compose run --rm api go run main.go` 确保 PDF 能够成功生成。
2.  [x] **后端 API (同步)：**
    * 使用 `GORM` 定义 `Resume` 和 `User` 结构体。
    * 在 Gin 启动时运行 `gorm.AutoMigrate`。
    * 实现 **`POST /v1/resume`**：(暂时无需认证) 接收 JSON，存入 `db`。
    * 实现 **`GET /v1/resume/:id/download`**：
        1.  用 GORM 从 `db` 查询简历数据。
        2.  使用 `html/template` 将数据渲染为 HTML 字符串。
        3.  **同步调用 `go-rod`** 将 HTML 字符串转为 PDF (存在内存 `bytes.Buffer`中)。
        4.  设置 `Content-Type: application/pdf`，将 PDF 字节流直接返回给用户。
3.  [x] **前端 UI：**
    * 创建一个简单的简历表单（用 `<textarea>` 即可）。
    * "保存" 按钮：调用 `POST /api/v1/resume`。
    * "下载" 按钮：`window.open('/api/v1/resume/123/download')` 来触发下载。

**验收标准：**
* 用户可以在前端页面输入 "Hello"，点击保存。
* 点击下载，浏览器能**立即**下载一份由 `go-rod` 动态生成的、内容为 "Hello" 的 PDF。

---

## Phase 2: 异步处理与文件存储

**目标：** 将**同步**的 PDF 生成重构为**异步**任务，实现你的目标架构，提高 API 响应能力。

**组件：** `Asynq`, `Redis`, `Go Worker`, `阿里云 OSS` (开发时用 `MinIO` 替代)

**任务：**

1. [x] **环境 (`docker-compose.yml`)：**
    * 添加 `redis` (使用 `redis:7-alpine` 镜像)。
    * 添加 `minio` (使用 `minio/minio` 镜像) 作为开发期的对象存储。
    * 添加 `worker` 服务：
        * 创建 `/backend/worker/Dockerfile.worker` (同样需要 `chromium` 依赖)。
        * 创建 `/backend/worker/main.go` 作为 Asynq Server 的启动入口。
2. [x] **后端 API (重构)：**
    * **重构 `GET /v1/resume/:id/download` 路由：**
        1.  移除所有 `go-rod` 调用。
        2.  改为使用 `Asynq Client` 将一个 `pdf:generate` 任务 (包含 `resume_id`) 推送到 `Redis`。
        3.  立即返回 `HTTP 202 Accepted` (表示任务已接收)。
    * **日志：** 在 Gin 中集成 `slog`，并创建中间件**生成 Correlation ID (关联ID)**。
    * **任务：** 将 Correlation ID 作为元数据存入 `Asynq` 任务。
3. [x] **Go Worker (新服务)：**
    * 在 `worker` 的 `main.go` 中，启动 `Asynq Server`。
    * 注册 `pdf:generate` 任务的处理器 (Handler)。
    * **迁移逻辑：** 将 Phase 1 中的 `go-rod` PDF 生成逻辑**完整迁移**到这里。
    * **日志：** 从任务元数据中**提取 Correlation ID**，并将其用于 `worker` 的所有 `slog` 日志。
    * **上传：** 生成 PDF 后，使用 `aws-sdk-go` (S3 兼容) 上传到 `MinIO/OSS`。
    * **更新：** 上传成功后，用 `GORM` 更新 `resumes` 表中的 `pdf_url` 和 `status` 字段。

**验收标准：**
* 点击“生成 PDF”按钮，前端**立即**收到 `HTTP 202` 响应。
* `worker` 服务的日志显示它接收到了任务（并打印了正确的 Correlation ID），成功生成了 PDF，并上传到了 MinIO。
* 数据库中的 `pdf_url` 字段被更新。

---

## Phase 3: 认证与实时通知

**目标：** 增加用户系统，保护 API，并通过 WebSocket 闭合异步通知的体验环。

**组件：** `JWT (RS256)`, `WebSockets`

**任务：**

1.  **身份认证 (API)：**
    * 实现用户注册 `POST /v1/auth/register`。
    * 实现登录 `POST /v1/auth/login` (返回 `JWT` 和 `Refresh Token`)。
    * 实现 `POST /v1/auth/refresh` (刷新令牌)。
    * 实现 `POST /v1/auth/logout` (利用 Redis 实现 Refresh Token 吊销)。
    * 创建 `JWT` 中间件，并用它保护所有 `resume` 相关的 API 路由。
2.  **前端 (认证)：**
    * 创建登录/注册页面。
    * 实现 Token 的安全存储（例如 Refresh Token 存 `HttpOnly Cookie`）。
    * 配置 API 请求自动携带 `JWT` (Authorization Header)。
3.  **实时通知 (API)：**
    * 添加一个 `GET /ws` 路由，用于建立 `WebSocket` 连接（需 JWT 认证）。
    * `worker` 在 Phase 2 中完成任务后，额外向 `Redis Pub/Sub` 发布一条“完成”消息（例如 `channel: user_123`）。
    * `api` 服务的 WebSocket 处理器负责订阅对应用户的 `Redis Pub/Sub` 频道，并在收到消息时，将“完成”事件（含 `pdf_url`）推送给前端。
4.  **前端 (通知)：**
    * 在点击“生成 PDF”后，同时建立 WebSocket 连接。
    * 监听“完成”事件，当收到消息时，UI 自动更新（例如从“生成中...”变为“下载”按钮）。

**验收标准：**
* 未登录用户无法访问 /api/v1/resume 路由。
* 用户点击“生成 PDF”后，UI 显示“生成中...”。几秒后，（无需刷新）按钮自动变为“下载”，且链接指向正确的 OSS URL。

---

## Phase 4: 可观测性与安全强化

**目标：** 集成日志和监控系统，使系统可被观测。强化文件上传安全。

**组件：** `Loki`, `Promtail`, `Prometheus`, `Grafana`, `ClamAV`

**任务：**

1.  **日志系统 (`docker-compose.yml`)：**
    * 添加 `loki` 服务。
    * 添加 `promtail` 服务，配置其抓取 `api`, `worker`, `nginx` 容器的 `stdout` 日志。
2.  **指标系统 (`docker-compose.yml`)：**
    * 添加 `prometheus` 服务。
    * 添加 `grafana` 服务，并配置 `loki` 和 `prometheus` 为数据源。
3.  **应用暴露指标 (Code)：**
    * `api` (Gin): 添加 `gin-prometheus` 中间件，暴露 `/metrics` 接口。
    * `worker` (Asynq): 启用 `Asynq` 的 Prometheus 监控（它内置了支持）。
4.  **安全（`ClamAV`）：**
    * *（如果你的网站允许用户上传，如头像）*
    * 在 `docker-compose.yml` 中添加 `clamav/clamav` 服务。
    * 在 `api` 服务中添加文件上传接口。
    * 在将文件上传到 `OSS` **之前**，先把文件流发送给 `ClamAV` 服务进行扫描，拒绝恶意文件。
5.  **仪表盘 (Grafana)：**
    * 创建一个 Grafana 仪表盘：
        * **日志：** 添加一个 Loki 面板，可以按 `app` (`api`/`worker`) 过滤，并能用 Correlation ID 搜索日志。
        * **指标：** 添加 API 延迟 (P95)、错误率、Asynq 队列深度等图表。

**验收标准：**
* 可以在 Grafana 仪表盘上看到 API 的 QPS、延迟和错误率。
* 可以在 Grafana 中搜索 `correlation_id="xyz"`，并同时看到 `api` 和 `worker` 的相关日志。

---

## Phase 5: CI/CD 与生产部署

**目标：** 自动化测试和部署流程，准备好向生产环境（容器+托管）迁移。

**组件：** `GitHub Actions`

**任务：**

1.  **CI (持续集成)：**
    * 创建 `.github/workflows/ci.yml`。
    * 触发器：`on: push` (所有分支)。
    * Jobs：
        * `test-backend`: 运行 `go test ./...`, `go vet`, `gofmt -C .`。
        * `test-frontend`: 运行 `npm test`。
2.  **CD (持续部署)：**
    * 创建 `.github/workflows/deploy.yml`。
    * 触发器：`on: push, branches: [ main ]` (仅 `main` 分支)。
    * Jobs：
        1.  (Secrets) 配置 `ALIYUN_REGISTRY_USER`, `ALIYUN_REGISTRY_TOKEN`, `OSS_KEY` 等密钥。
        2.  (Build & Push) 登录阿里云镜像仓库 (ACR)，构建 `api`, `worker`, `frontend` 镜像，并推送。
        3.  (Deploy) SSH 登录到你的生产服务器，执行 `docker-compose pull` 和 `docker-compose up -d` 来更新服务。
3.  **生产环境准备 (托管)：**
    * 将 `docker-compose.yml` 中的 `db`, `redis` 替换为阿里云 `RDS (PostgreSQL)` 和 `ApsaraCache (Redis)` 的连接字符串。
    * `MinIO` 替换为 `阿里云 OSS` 的生产环境 Bucket。
    * `Loki/Prometheus` 替换为阿里云 `SLS` (日志) 和 `ARMS` (监控)（可选，也可以继续自建）。

**验收标准：**
* 向 `main` 分支 `git push` 一次代码，几分钟后，生产环境的网站自动更新为最新版本。

---

### Phase 0 Step 5 后续优化清单

- [ ] 启用 `gzip`/`brotli` 压缩以降低静态资源体积。
- [ ] 为静态资源与 API 响应补充合适的缓存与安全头。
- [ ] 配置独立的访问日志与错误日志并对接 Loki。
